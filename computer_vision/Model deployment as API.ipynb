{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b6953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array \n",
    "from flask import Flask, jsonify, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38efccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 13:58:57.936998: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-09-14 13:58:57.937277: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('models/MobNet_model_3classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f74da014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_defect(image_path):\n",
    "    img = load_img(image_path, target_size= (224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    #img = cv2.imread(image_path)\n",
    "    #resize = tf.image.resize(img, (224,224))\n",
    "    yhat = model.predict(np.expand_dims(img/255, 0)).argmax(axis=1)\n",
    "    if yhat == 0:\n",
    "        pred = 'crack'\n",
    "    elif yhat == 1:\n",
    "        pred = 'pothole'\n",
    "    else:\n",
    "        pred = 'rut'\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310be205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 13:54:54.052241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 822ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'crack'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict_defect('road_images/im_to_test/crack3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed69af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "\n",
    "def infer_image():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify(error=\"Please try again. The image doesn't exist\")\n",
    "    \n",
    "    file = request.files.get('file')\n",
    "    img_bytes = file.read()\n",
    "    img_path = \"./road_images/im_to_test/crack3.jpg\"\n",
    "    with open(img_path, \"wb\") as img:\n",
    "        img.write(img_bytes)\n",
    "    result = predict_defect(img_path)\n",
    "    return jsonify(prediction=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a1611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [14/Sep/2023 13:59:07] \"\u001b[31m\u001b[1mGET / HTTP/1.1\u001b[0m\" 405 -\n",
      "2023-09-14 13:59:16.396458: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 794ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Sep/2023 13:59:16] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Sep/2023 14:49:14] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
